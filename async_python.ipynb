{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async Python: \n",
    "# The Different Forms of Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Recap\n",
    "So this is what we have realized so far:\n",
    "\n",
    "* Sync: Blocking operations.\n",
    "* Async: Non blocking operations.\n",
    "* Concurrency: Making progress together.\n",
    "* Parallelism: Making progress in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has had Threads for a very long time. Threads allow us to run our operations concurrently. But there was/is a problem with the Global Interpreter Lock (GIL) for which the threading could not provide true parallelism. However, with multiprocessing, it is now possible to leverage multiple cores with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Threads are queued, let's see when they finish!\n",
      "I am Worker 0, I slept for 2 seconds\n",
      "I am Worker 3, I slept for 3 seconds\n",
      "I am Worker 1, I slept for 7 seconds\n",
      "I am Worker 2, I slept for 9 seconds\n",
      "I am Worker 4, I slept for 9 seconds\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "def worker(number):\n",
    "    sleep = random.randrange(1, 10)\n",
    "    time.sleep(sleep)\n",
    "    print(\"I am Worker {}, I slept for {} seconds\".format(number, sleep))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    t.start()\n",
    "\n",
    "print(\"All Threads are queued, let's see when they finish!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Interpreter Lock (GIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One thread can run at a time.\n",
    "* The Python Interpreter switches between threads to allow concurrency.\n",
    "* The GIL is only applicable to CPython (the defacto implementation). Other implementations like Jython, IronPython don’t have GIL.\n",
    "* GIL makes single threaded programs fast.\n",
    "* For I/O bound operations, GIL usually doesn’t harm much.\n",
    "* GIL makes it easy to integrate non thread safe C libraries, thansk to the GIL, we have many high performance extensions/modules written in C.\n",
    "* For CPU bound tasks, the interpreter checks between N ticks and switches threads. So one thread does not block others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Processes are queued, let's see when they finish!\n",
      "I am Worker 4, I slept for 2 seconds\n",
      "I am Worker 2, I slept for 6 seconds\n",
      "I am Worker 3, I slept for 7 seconds\n",
      "I am Worker 1, I slept for 8 seconds\n",
      "I am Worker 0, I slept for 8 seconds\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "def worker(number):\n",
    "    sleep = random.randrange(1, 10)\n",
    "    time.sleep(sleep)\n",
    "    print(\"I am Worker {}, I slept for {} seconds\".format(number, sleep))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    t = multiprocessing.Process(target=worker, args=(i,))\n",
    "    t.start()\n",
    "\n",
    "print(\"All Processes are queued, let's see when they finish!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Pool class, we can also distribute one function execution across multiple processes for different input values. If we take the example from the official docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(5)\n",
    "    print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, instead of iterating over the list of values and calling f on them one by one, we are actually running the function on different processes. One process executes f(1), another runs f(2) and another runs f(3). Finally the results are again aggregated in a list. This would allow us to break down heavy computations into smaller parts and run them in parallel for faster calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The concurrent.futures module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concurrent.futures module packs some really great stuff for writing async codes easily. My favorites are the ThreadPoolExecutor and the ProcessPoolExecutor. These executors maintain a pool of threads or processes. We submit our tasks to the pool and it runs the tasks in available thread/process. A Future object is returned which we can use to query and get the result when the task has completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from time import sleep\n",
    " \n",
    "def return_after_5_secs(message):\n",
    "    sleep(5)\n",
    "    return message\n",
    " \n",
    "pool = ThreadPoolExecutor(3)\n",
    " \n",
    "future = pool.submit(return_after_5_secs, (\"hello\"))\n",
    "print(future.done())\n",
    "sleep(5)\n",
    "print(future.done())\n",
    "print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asyncio - Why, What and How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3d26734c9173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This event loop is already running'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop: 1 Time: 2019-01-09 15:07:05.601780\n",
      "Loop: 2 Time: 2019-01-09 15:07:05.601923\n",
      "Loop: 2 Time: 2019-01-09 15:07:06.603976\n",
      "Loop: 2 Time: 2019-01-09 15:07:08.606170\n",
      "Loop: 1 Time: 2019-01-09 15:07:09.603845\n",
      "Loop: 2 Time: 2019-01-09 15:07:12.608543\n",
      "Loop: 1 Time: 2019-01-09 15:07:14.607422\n",
      "Loop: 2 Time: 2019-01-09 15:07:14.610369\n",
      "Loop: 1 Time: 2019-01-09 15:07:16.611080\n",
      "Loop: 1 Time: 2019-01-09 15:07:17.612879\n",
      "Loop: 2 Time: 2019-01-09 15:07:18.612759\n",
      "Loop: 2 Time: 2019-01-09 15:07:21.615997\n",
      "Loop: 1 Time: 2019-01-09 15:07:21.616366\n",
      "Loop: 1 Time: 2019-01-09 15:07:25.620888\n",
      "Loop: 2 Time: 2019-01-09 15:07:26.617913\n",
      "Loop: 1 Time: 2019-01-09 15:07:27.623849\n",
      "Loop: 2 Time: 2019-01-09 15:07:29.621666\n",
      "Loop: 1 Time: 2019-01-09 15:07:31.627451\n",
      "Loop: 2 Time: 2019-01-09 15:07:34.626050\n",
      "Loop: 1 Time: 2019-01-09 15:07:34.628731\n",
      "Loop: 2 Time: 2019-01-09 15:07:35.628248\n",
      "Loop: 1 Time: 2019-01-09 15:07:35.629765\n",
      "Loop: 1 Time: 2019-01-09 15:07:38.633137\n",
      "Loop: 2 Time: 2019-01-09 15:07:39.630841\n",
      "Loop: 1 Time: 2019-01-09 15:07:40.634271\n",
      "Loop: 1 Time: 2019-01-09 15:07:42.636958\n",
      "Loop: 1 Time: 2019-01-09 15:07:42.637360\n",
      "Loop: 2 Time: 2019-01-09 15:07:44.633924\n",
      "Loop: 2 Time: 2019-01-09 15:07:47.637634\n",
      "Loop: 1 Time: 2019-01-09 15:07:47.639180\n",
      "Loop: 1 Time: 2019-01-09 15:07:49.641982\n",
      "Loop: 2 Time: 2019-01-09 15:07:52.642941\n",
      "Loop: 1 Time: 2019-01-09 15:07:52.643351\n",
      "Loop: 1 Time: 2019-01-09 15:07:52.643548\n",
      "Loop: 1 Time: 2019-01-09 15:07:54.646296\n",
      "Loop: 2 Time: 2019-01-09 15:07:57.647195\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "async def my_sleep_func():\n",
    "    await asyncio.sleep(random.randint(0, 5))\n",
    "\n",
    "\n",
    "async def display_date(num, loop):\n",
    "    end_time = loop.time() + 50.0\n",
    "    while True:\n",
    "        print(\"Loop: {} Time: {}\".format(num, datetime.datetime.now()))\n",
    "        if (loop.time() + 1.0) >= end_time:\n",
    "            break\n",
    "        await my_sleep_func()\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "asyncio.ensure_future(display_date(1, loop))\n",
    "asyncio.ensure_future(display_date(2, loop))\n",
    "\n",
    "loop.run_forever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have an async function display_date which takes a number (as an identifier) and the event loop as parameters.\n",
    "* The function has an infinite loop that breaks after 50 secs. But during this 50 sec period, it repeatedly prints out the time and takes a nap. The await function can wait on other async functions (coroutines) to complete.\n",
    "* We pass the function to event loop (using the ensure_future method).\n",
    "* We start running the event loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if io_bound:\n",
    "    if io_very_slow:\n",
    "        use(\"Use Asyncio\")\n",
    "    else:\n",
    "        use(\"Use Threads\")\n",
    "else:\n",
    "    use(\"Multi Processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CPU Bound => Multi Processing\n",
    "* I/O Bound, Fast I/O, Limited Number of Connections => Multi Threading\n",
    "* I/O Bound, Slow I/O, Many connections => Asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
