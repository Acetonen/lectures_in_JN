{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concurent.futures Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concurrent.futures module is part of the standard library which provides a high level API for launching async tasks. We will discuss and go through code samples for the common usages of this module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executors\n",
    "\n",
    "This module features the Executor class which is an abstract class and it can not be used directly. However it has two very useful concrete subclasses – ThreadPoolExecutor and ProcessPoolExecutor. As their names suggest, one uses multi threading and the other one uses multi-processing. In both case, we get a pool of threads or processes and we can submit tasks to this pool. The pool would assign tasks to the available resources (threads or processes) and schedule them to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ThreadPoolExecutor\n",
    "(use threading module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from time import sleep\n",
    " \n",
    "def return_after_5_secs(message):\n",
    "    sleep(5)\n",
    "    return message\n",
    " \n",
    "pool = ThreadPoolExecutor(3)  # Number of threads in pool.\n",
    " \n",
    "future = pool.submit(return_after_5_secs, (\"hello\"))\n",
    "print(future.done())\n",
    "sleep(5)\n",
    "print(future.done())\n",
    "print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProcessPoolExecutor\n",
    "!!! Can use only picklable objects !!!\n",
    "\n",
    "(use multiprocessing module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "Result: hello\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from time import sleep\n",
    " \n",
    "def return_after_5_secs(message):\n",
    "    sleep(5)\n",
    "    return message\n",
    " \n",
    "pool = ProcessPoolExecutor(3)\n",
    " \n",
    "future = pool.submit(return_after_5_secs, (\"hello\"))\n",
    "print(future.done())\n",
    "sleep(6)\n",
    "print(future.done())\n",
    "print(\"Result: \" + future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executor.map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ThreadPoolExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://www.foxnews.com/' page is 224130 bytes\n",
      "'http://some-made-up-domain.com/' page is 4028 bytes\n",
      "'http://europe.wsj.com/' page is 923572 bytes\n",
      "'http://www.bbc.co.uk/' page is 297709 bytes\n",
      "'http://www.cnn.com/' page is 1885324 bytes\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import urllib.request\n",
    " \n",
    "URLS = ['http://www.foxnews.com/',\n",
    "        'http://www.cnn.com/',\n",
    "        'http://europe.wsj.com/',\n",
    "        'http://www.bbc.co.uk/',\n",
    "        'http://some-made-up-domain.com/']\n",
    " \n",
    "# Retrieve a single page and report the url and contents\n",
    "def load_url(url, timeout):\n",
    "    with urllib.request.urlopen(url, timeout=timeout) as conn:\n",
    "        return conn.read()\n",
    " \n",
    "# We can use a with statement to ensure threads are cleaned up promptly\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Start the load operations and mark each future with its URL\n",
    "    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (url, exc))\n",
    "        else:\n",
    "            print('%r page is %d bytes' % (url, len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: starting\n",
      "ThreadPoolExecutor-10_0: sleeping 5\n",
      "ThreadPoolExecutor-10_1: sleeping 4\n",
      "main: unprocessed results <generator object Executor.map.<locals>.result_iterator at 0x7fcf24041e08>\n",
      "main: waiting for real results\n",
      "ThreadPoolExecutor-10_1: done with 4\n",
      "ThreadPoolExecutor-10_1: sleeping 3\n",
      "ThreadPoolExecutor-10_0: done with 5\n",
      "ThreadPoolExecutor-10_0: sleeping 2\n",
      "ThreadPoolExecutor-10_0: done with 2\n",
      "ThreadPoolExecutor-10_0: sleeping 1\n",
      "ThreadPoolExecutor-10_1: done with 3\n",
      "ThreadPoolExecutor-10_0: done with 1\n",
      "main: results: [0.5, 0.4, 0.3, 0.2, 0.1]\n"
     ]
    }
   ],
   "source": [
    "# futures_thread_pool_map.py\n",
    "from concurrent import futures\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{}: sleeping {}'.format(\n",
    "        threading.current_thread().name,\n",
    "        n)\n",
    "    )\n",
    "    time.sleep(n / 10)\n",
    "    print('{}: done with {}'.format(\n",
    "        threading.current_thread().name,\n",
    "        n)\n",
    "    )\n",
    "    return n / 10\n",
    "\n",
    "\n",
    "ex = futures.ThreadPoolExecutor(max_workers=2)\n",
    "print('main: starting')\n",
    "results = ex.map(task, range(5, 0, -1))\n",
    "print('main: unprocessed results {}'.format(results))\n",
    "print('main: waiting for real results')\n",
    "real_results = list(results)\n",
    "print('main: results: {}'.format(real_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ProcessPoolExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112272535095293 is prime: True\n",
      "112582705942171 is prime: True\n",
      "112272535095293 is prime: True\n",
      "115280095190773 is prime: True\n",
      "115797848077099 is prime: True\n",
      "1099726899285419 is prime: False\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    " \n",
    "PRIMES = [\n",
    "    112272535095293,\n",
    "    112582705942171,\n",
    "    112272535095293,\n",
    "    115280095190773,\n",
    "    115797848077099,\n",
    "    1099726899285419]\n",
    " \n",
    "def is_prime(n):\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    " \n",
    "    sqrt_n = int(math.floor(math.sqrt(n)))\n",
    "    for i in range(3, sqrt_n + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    " \n",
    "def main():\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):\n",
    "            print('%d is prime: %s' % (number, prime))\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduling Individual Tasks\n",
    "In addition to using map(), it is possible to schedule an individual task with an executor using submit(), and use the Future instance returned to wait for that task’s results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: starting\n",
      "ThreadPoolExecutor-11_0: sleeping 5\n",
      "main: future: <Future at 0x7fcf241e19e8 state=running>\n",
      "main: waiting for results\n",
      "ThreadPoolExecutor-11_0: done with 5\n",
      "main: result: 0.5\n",
      "main: future after result: <Future at 0x7fcf241e19e8 state=finished returned float>\n"
     ]
    }
   ],
   "source": [
    "# futures_thread_pool_submit.py\n",
    "from concurrent import futures\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{}: sleeping {}'.format(\n",
    "        threading.current_thread().name,\n",
    "        n)\n",
    "    )\n",
    "    time.sleep(n / 10)\n",
    "    print('{}: done with {}'.format(\n",
    "        threading.current_thread().name,\n",
    "        n)\n",
    "    )\n",
    "    return n / 10\n",
    "\n",
    "\n",
    "ex = futures.ThreadPoolExecutor(max_workers=2)\n",
    "print('main: starting')\n",
    "f = ex.submit(task, 5)\n",
    "print('main: future: {}'.format(f))\n",
    "print('main: waiting for results')\n",
    "result = f.result()\n",
    "print('main: result: {}'.format(result))\n",
    "print('main: future after result: {}'.format(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### as_complete() & wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concurrent.futures module has two functions for dealing with the futures returned by the executors. One is as_completed() and the other one is wait().\n",
    "\n",
    "The as_completed() function takes an iterable of Future objects and starts yielding values as soon as the futures start resolving. The main difference between the aforementioned map method with as_completed is that map returns the results in the order in which we pass the iterables. That is the first result from the map method is the result for the first item. On the other hand, the first result from the as_completed function is from whichever future completed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return of 0\n",
      "Return of 2\n",
      "Return of 1\n",
      "Return of 3\n",
      "Return of 4\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, wait, as_completed\n",
    "from time import sleep\n",
    "from random import randint\n",
    " \n",
    "def return_after_5_secs(num):\n",
    "    sleep(randint(1, 5))\n",
    "    return \"Return of {}\".format(num)\n",
    " \n",
    "pool = ThreadPoolExecutor(5)\n",
    "futures = []\n",
    "for x in range(5):\n",
    "    futures.append(pool.submit(return_after_5_secs, x))\n",
    " \n",
    "for x in as_completed(futures):\n",
    "    print(x.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wait() function would return a named tuple which contains two set – one set contains the futures which completed (either got result or exception) and the other set containing the ones which didn’t complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DoneAndNotDoneFutures(done={<Future at 0x7fcf242022e8 state=finished returned str>}, not_done={<Future at 0x7fcf241f4c88 state=running>, <Future at 0x7fcf241520b8 state=running>, <Future at 0x7fcf241e19e8 state=running>, <Future at 0x7fcf24202278 state=running>})\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, wait, as_completed\n",
    "from time import sleep\n",
    "from random import randint\n",
    " \n",
    "def return_after_5_secs(num):\n",
    "    sleep(randint(1, 5))\n",
    "    return \"Return of {}\".format(num)\n",
    " \n",
    "pool = ThreadPoolExecutor(5)\n",
    "futures = []\n",
    "for x in range(5):\n",
    "    futures.append(pool.submit(return_after_5_secs, x))\n",
    " \n",
    "print(wait(futures, return_when='FIRST_COMPLETED'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can control the behavior of the wait function by defining when it should return. We can pass one of these values to the return_when param of the function: FIRST_COMPLETED, FIRST_EXCEPTION and ALL_COMPLETED. By default, it’s set to ALL_COMPLETED, so the wait function returns only when all futures complete. But using that parameter, we can choose to return when the first future completes or first exception encounters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take some action when a task completed, without explicitly waiting for the result, use add_done_callback() to specify a new function to call when the Future is done. The callback should be a callable taking a single argument, the Future instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: starting\n",
      "5: sleeping\n",
      "5: done\n",
      "5: value returned: 0.5\n"
     ]
    }
   ],
   "source": [
    "# futures_future_callback.py\n",
    "from concurrent import futures\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{}: sleeping'.format(n))\n",
    "    time.sleep(0.5)\n",
    "    print('{}: done'.format(n))\n",
    "    return n / 10\n",
    "\n",
    "\n",
    "def done(fn):\n",
    "    if fn.cancelled():\n",
    "        print('{}: canceled'.format(fn.arg))\n",
    "    elif fn.done():\n",
    "        error = fn.exception()\n",
    "        if error:\n",
    "            print('{}: error returned: {}'.format(\n",
    "                fn.arg, error))\n",
    "        else:\n",
    "            result = fn.result()\n",
    "            print('{}: value returned: {}'.format(\n",
    "                fn.arg, result))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ex = futures.ThreadPoolExecutor(max_workers=2)\n",
    "    print('main: starting')\n",
    "    f = ex.submit(task, 5)\n",
    "    f.arg = 5\n",
    "    f.add_done_callback(done)\n",
    "    result = f.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canceling Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: starting\n",
      "main: submitting 10\n",
      "10: sleeping\n",
      "main: submitting 9\n",
      "9: sleeping\n",
      "main: submitting 8\n",
      "main: submitting 7\n",
      "main: submitting 6\n",
      "main: submitting 5\n",
      "main: submitting 4\n",
      "main: submitting 3\n",
      "main: submitting 2\n",
      "main: submitting 1\n",
      "1: canceled\n",
      "2: canceled\n",
      "3: canceled\n",
      "4: canceled\n",
      "5: canceled\n",
      "6: canceled\n",
      "7: canceled\n",
      "8: canceled\n",
      "main: did not cancel 9\n",
      "main: did not cancel 10\n",
      "10: done\n",
      "10: not canceled\n",
      "9: done\n",
      "9: not canceled\n"
     ]
    }
   ],
   "source": [
    "# futures_future_callback_cancel.py\n",
    "from concurrent import futures\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{}: sleeping'.format(n))\n",
    "    time.sleep(0.5)\n",
    "    print('{}: done'.format(n))\n",
    "    return n / 10\n",
    "\n",
    "\n",
    "def done(fn):\n",
    "    if fn.cancelled():\n",
    "        print('{}: canceled'.format(fn.arg))\n",
    "    elif fn.done():\n",
    "        print('{}: not canceled'.format(fn.arg))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ex = futures.ThreadPoolExecutor(max_workers=2)\n",
    "    print('main: starting')\n",
    "    tasks = []\n",
    "\n",
    "    for i in range(10, 0, -1):\n",
    "        print('main: submitting {}'.format(i))\n",
    "        f = ex.submit(task, i)\n",
    "        f.arg = i\n",
    "        f.add_done_callback(done)\n",
    "        tasks.append((i, f))\n",
    "\n",
    "    for i, t in reversed(tasks):\n",
    "        if not t.cancel():\n",
    "            print('main: did not cancel {}'.format(i))\n",
    "\n",
    "    ex.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptions in Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: starting\n",
      "5: starting\n",
      "main: error: the value 5 is no good\n",
      "main: saw error \"the value 5 is no good\" when accessing result\n"
     ]
    }
   ],
   "source": [
    "# futures_future_exception.py\n",
    "from concurrent import futures\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{}: starting'.format(n))\n",
    "    raise ValueError('the value {} is no good'.format(n))\n",
    "\n",
    "\n",
    "ex = futures.ThreadPoolExecutor(max_workers=2)\n",
    "print('main: starting')\n",
    "f = ex.submit(task, 5)\n",
    "\n",
    "error = f.exception()\n",
    "print('main: error: {}'.format(error))\n",
    "\n",
    "try:\n",
    "    result = f.result()\n",
    "except ValueError as e:\n",
    "    print('main: saw error \"{}\" when accessing result'.format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Manager`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: starting\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "main: done\n"
     ]
    }
   ],
   "source": [
    "# futures_context_manager.py\n",
    "from concurrent import futures\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print(n)\n",
    "\n",
    "\n",
    "with futures.ThreadPoolExecutor(max_workers=2) as ex:\n",
    "    print('main: starting')\n",
    "    ex.submit(task, 1)\n",
    "    ex.submit(task, 2)\n",
    "    ex.submit(task, 3)\n",
    "    ex.submit(task, 4)\n",
    "\n",
    "print('main: done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran task 5 in process 14827\n",
      "ran task 4 in process 14828\n",
      "ran task 3 in process 14827\n",
      "ran task 2 in process 14827\n",
      "ran task 1 in process 14828\n"
     ]
    }
   ],
   "source": [
    "# futures_process_pool_map.py\n",
    "from concurrent import futures\n",
    "import os\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    return (n, os.getpid())\n",
    "\n",
    "\n",
    "ex = futures.ProcessPoolExecutor(max_workers=2)\n",
    "results = ex.map(task, range(5, 0, -1))\n",
    "for n, pid in results:\n",
    "    print('ran task {} in process {}'.format(n, pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If something happens to one of the worker processes to cause it to exit unexpectedly, the ProcessPoolExecutor is considered “broken” and will no longer schedule tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting the pid for one worker\n",
      "killing process 14836\n",
      "submitting another task\n"
     ]
    }
   ],
   "source": [
    "# futures_process_pool_broken.py\n",
    "from concurrent import futures\n",
    "import os\n",
    "import signal\n",
    "\n",
    "\n",
    "with futures.ProcessPoolExecutor(max_workers=2) as ex:\n",
    "    print('getting the pid for one worker')\n",
    "    f1 = ex.submit(os.getpid)\n",
    "    pid1 = f1.result()\n",
    "\n",
    "    print('killing process {}'.format(pid1))\n",
    "    os.kill(pid1, signal.SIGHUP)\n",
    "\n",
    "    print('submitting another task')\n",
    "    f2 = ex.submit(os.getpid)\n",
    "    try:\n",
    "        pid2 = f2.result()\n",
    "    except futures.process.BrokenProcessPool as e:\n",
    "        print('could not start new tasks: {}'.format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
